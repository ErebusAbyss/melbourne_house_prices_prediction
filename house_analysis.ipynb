{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb6b65bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, GradientBoostingRegressor\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mean_absolute_error, mean_squared_error, r2_score\n\u001b[32m     16\u001b[39m df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mmelb_data.csv\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from numpy import square\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "df = pd.read_csv('melb_data.csv')\n",
    "\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nInfo about the dataset:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "#Vizualization\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['Price'], bins=30)\n",
    "plt.title('Distribution of House Prices')\n",
    "plt.xlabel('Price (AUD)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "#Analysing of the columns\n",
    "important_cols = [ 'Suburb', 'Rooms', 'Type', 'Distance', 'Bedroom2', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Regionname', 'Propertycount']\n",
    "df = df[important_cols + ['Price']]\n",
    "\n",
    "print(\"\\nSelected columns:\")\n",
    "print(df.columns)\n",
    "\n",
    "#Preprocessing data\n",
    "#Cheking for incorrect values and processing them\n",
    "print(\"\\nMissing values:\", df.isnull().sum())\n",
    "\n",
    "for col in df.columns:\n",
    "    unique_count = df[col].nunique()\n",
    "    dup_pct = ((len(df) - unique_count) / len(df)) * 100\n",
    "    print(f\"\\n{col}: Unique = {unique_count}, Duplicate % = {dup_pct:.1f}%\")\n",
    "\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nUnique values in '{col}' (top 10):\")\n",
    "    print(df[col].value_counts().head(10))\n",
    "    print(f\"Total unique: {df[col].nunique()}\")\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.drop('Price')\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\nOutliers in '{col}:\")\n",
    "    print(df[col].describe())\n",
    "    #Z-score\n",
    "    z_scores = (df[col] - df[col].mean()) / df[col].std()\n",
    "    outiers_z = df[col][abs(z_scores) > 3]\n",
    "    print(f\"Z-score outliers (>3 std): {len(outiers_z)} values, e.g. {outiers_z.head().tolist()}\")\n",
    "    #IQR\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers_iqr = df[col][(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n",
    "    print(f\"IQR outliers: {len(outliers_iqr)} values\")\n",
    "\n",
    "print(\"\\nChecking for extra characters in text columns:\")\n",
    "for col in categorical_cols:\n",
    "    has_extra_chars = df[col].str.contains(r'[^a-zA-Z\\s]', na=False).sum()\n",
    "    if has_extra_chars > 0:\n",
    "        print(f\"{col}: Found {has_extra_chars} rows with extra characters, e.g.:\")\n",
    "        print(df[col][df[col].str.contains(r'[^a-zA-Z\\s]', na=False)].head().tolist())\n",
    "    else:\n",
    "        print(f\"{col}: No extra characters found.\")\n",
    "\n",
    "#Boxplot for vizualization(first 4 numeric)\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, col in enumerate(numeric_cols[:4], 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Correlation\n",
    "corr_rooms_price = df['Rooms'].corr(df['Price'])\n",
    "corr_bedroom2_price = df['Bedroom2'].corr(df['Price'])\n",
    "print(f\"Correlation Rooms vs Price: {corr_rooms_price:.3f}\")\n",
    "print(f\"Correlation Bedroom2 vs Price: {corr_bedroom2_price:.3f}\")\n",
    "\n",
    "corr_rooms_bedroom2 = df['Rooms'].corr(df['Bedroom2'])\n",
    "print(f\"Correlation Rooms vs Bedroom2: {corr_rooms_bedroom2:.3f}\")\n",
    "\n",
    "corr_propertycount_price = df['Propertycount'].corr(df['Price'])\n",
    "print(f\"Correlation Propertycount vs Price: {corr_propertycount_price:.3f}\")\n",
    "\n",
    "df = df.drop(['Propertycount', 'Bedroom2'], axis=1)\n",
    "\n",
    "#Handling missing values\n",
    "df['Car'] = df['Car'].fillna(df['Car'].median())\n",
    "\n",
    "cols_for_building = ['Rooms', 'Bathroom', 'Landsize']\n",
    "imputer_building = KNNImputer(n_neighbors=5)\n",
    "df[cols_for_building + ['BuildingArea']] = imputer_building.fit_transform(df[cols_for_building + ['BuildingArea']])\n",
    "\n",
    "cols_for_year = ['Rooms', 'BuildingArea', 'Landsize']\n",
    "imputer_year = KNNImputer(n_neighbors=5)\n",
    "df[cols_for_year + ['YearBuilt']] = imputer_year.fit_transform(df[cols_for_year + ['YearBuilt']])\n",
    "\n",
    "print(\"\\nMissing values after KNN:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Handling outliers\n",
    "bathroom_99 = df['Bathroom'].quantile(0.99)\n",
    "df.loc[df['Bathroom'] > 4, 'Bathroom'] = bathroom_99\n",
    "\n",
    "median_car = df['Car'].median()\n",
    "df.loc[df['Car'] > 4, 'Car'] = median_car\n",
    "\n",
    "landsiz_99 = df['Landsize'].quantile(0.99)\n",
    "df.loc[df['Landsize'] > landsiz_99, 'Landsize'] = landsiz_99\n",
    "\n",
    "building_99 = df['BuildingArea'].quantile(0.99)\n",
    "df.loc[df['BuildingArea'] > building_99, 'BuildingArea'] = building_99\n",
    "\n",
    "numeric_cols2 = df.select_dtypes(include=['int64', 'float64']).columns.drop('Price')\n",
    "for col in numeric_cols2:\n",
    "    print(f\"\\nOutliers in '{col}:\")\n",
    "    print(df[col].describe())\n",
    "    #Z-score\n",
    "    z_scores = (df[col] - df[col].mean()) / df[col].std()\n",
    "    outiers_z = df[col][abs(z_scores) > 3]\n",
    "    print(f\"Z-score outliers (>3 std): {len(outiers_z)} values, e.g. {outiers_z.head().tolist()}\")\n",
    "    #IQR\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers_iqr = df[col][(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)]\n",
    "    print(f\"IQR outliers: {len(outliers_iqr)} values\")\n",
    "\n",
    "#Normalization of categorical data\n",
    "#Grouping for high-cardinality\n",
    "threshold = 0.01\n",
    "value_counts = df[\"Suburb\"].value_counts(normalize=True)\n",
    "rare_suburbs = value_counts[value_counts < threshold].index\n",
    "df[\"Suburb\"] = df[\"Suburb\"].apply(lambda x: 'Other' if x in rare_suburbs else x)\n",
    "print(f\"Suburb unique after grouping: {df['Suburb'].nunique()}\")\n",
    "\n",
    "#LabelEncoder\n",
    "le = LabelEncoder()\n",
    "df['Suburb'] = le.fit_transform(df['Suburb'])\n",
    "\n",
    "#One-hot\n",
    "df = pd.get_dummies(df, columns=['Type', 'Regionname'], drop_first=True)\n",
    "\n",
    "#Normalization of numerical data\n",
    "numeric_cols_to_scale = ['Rooms', 'Bathroom', 'Car', 'Landsize', 'BuildingArea', 'YearBuilt', 'Distance']\n",
    "scaler = MinMaxScaler()\n",
    "df[numeric_cols_to_scale] = scaler.fit_transform(df[numeric_cols_to_scale])\n",
    "\n",
    "print(\"\\nFirst 5 rows after encoding and normalization:\")\n",
    "print(df.head())\n",
    "\n",
    "#Training and evaluation phase of models\n",
    "X = df.drop('Price', axis=1)\n",
    "y = df['Price']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42)    \n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {'MAE': mae, 'RMSE': rmse, 'R²': r2}\n",
    "\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"MAE = {mae:.2f}\")\n",
    "    print(f\"RMSE = {rmse:.2f}\")\n",
    "    print(f\"R² = {r2:.3f}\")\n",
    "\n",
    "best_model = min(results, key=lambda x: results[x]['RMSE'])\n",
    "print(f\"\\nThe best model by RMSE: {best_model} from RMSE = {results[best_model]['RMSE']:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
